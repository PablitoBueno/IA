# -*- coding: utf-8 -*-
"""depthMap.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hl7TaaB4CYLpUMHlh0m-5Of-QoFYkkq0
"""

from fastapi import FastAPI, File, UploadFile, Query, HTTPException
from fastapi.responses import StreamingResponse
from transformers import AutoProcessor, AutoModelForDepthEstimation
import torch
import cv2
import numpy as np
from PIL import Image
import io

# Inicialização do FastAPI
app = FastAPI()

# Carregar o processador e o modelo
model_id = "Intel/zoedepth-nyu"
processor = AutoProcessor.from_pretrained(model_id)
model = AutoModelForDepthEstimation.from_pretrained(model_id)

def preprocess_image(image_bytes: bytes):
    """Carrega e pré-processa a imagem a partir dos bytes."""
    img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    inputs = processor(images=img, return_tensors="pt")
    return img, inputs

def generate_depth_map(inputs):
    """Gera o mapa de profundidade a partir da imagem pré-processada."""
    with torch.no_grad():
        outputs = model(**inputs)
    depth_map = outputs.predicted_depth[0].squeeze().cpu().numpy()
    depth_map = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX)
    depth_map = np.uint8(depth_map)
    return depth_map

def apply_smoothing(depth_map, kernel_size: int = 5):
    """Aplica suavização com GaussianBlur ao mapa de profundidade."""
    # Garantir que o kernel seja ímpar
    if kernel_size % 2 == 0:
        kernel_size += 1
    return cv2.GaussianBlur(depth_map, (kernel_size, kernel_size), 0)

def apply_threshold(depth_map, min_depth: int, max_depth: int):
    """Aplica threshold para destacar objetos dentro de uma faixa de profundidade."""
    _, thresholded = cv2.threshold(depth_map, min_depth, max_depth, cv2.THRESH_BINARY)
    return thresholded

def visualize_depth_map(depth_map, mode: str = "gray", original_img: np.ndarray = None):
    """Converte o mapa de profundidade para o modo de visualização solicitado."""
    if mode == "gray":
        return depth_map
    elif mode == "color":
        return cv2.applyColorMap(depth_map, cv2.COLORMAP_PLASMA)
    elif mode == "overlay" and original_img is not None:
        depth_colored = cv2.applyColorMap(depth_map, cv2.COLORMAP_JET)
        return cv2.addWeighted(original_img, 0.6, depth_colored, 0.4, 0)
    else:
        raise ValueError("Modo inválido ou imagem original não fornecida para overlay.")

def detect_edges(depth_map):
    """Detecta bordas no mapa de profundidade utilizando o algoritmo Canny."""
    edges = cv2.Canny(depth_map, 50, 150)
    return edges

@app.post("/process_depth_map")
async def process_depth_map(
    file: UploadFile = File(..., description="Imagem a ser processada"),
    mode: str = Query("gray", description="Modo de visualização: 'gray', 'color' ou 'overlay'"),
    smoothing: bool = Query(False, description="Aplicar suavização?"),
    kernel_size: int = Query(5, description="Tamanho do kernel para suavização (número ímpar)"),
    threshold: bool = Query(False, description="Aplicar threshold?"),
    min_depth: int = Query(50, description="Valor mínimo para threshold"),
    max_depth: int = Query(200, description="Valor máximo para threshold"),
    edges: bool = Query(False, description="Aplicar detecção de bordas?")
):
    # Leitura e pré-processamento da imagem
    image_bytes = await file.read()
    try:
        original_img, inputs = preprocess_image(image_bytes)
    except Exception as e:
        raise HTTPException(status_code=400, detail="Erro ao processar a imagem.")

    # Geração do mapa de profundidade
    depth_map = generate_depth_map(inputs)

    # Aplicar suavização se solicitado
    if smoothing:
        depth_map = apply_smoothing(depth_map, kernel_size=kernel_size)

    # Aplicar threshold se solicitado
    if threshold:
        depth_map = apply_threshold(depth_map, min_depth, max_depth)

    # Aplicar detecção de bordas se solicitado
    if edges:
        depth_map = detect_edges(depth_map)

    # Configurar visualização
    if mode == "overlay":
        # Converter imagem original para o formato BGR necessário
        original_img_cv = cv2.cvtColor(np.array(original_img), cv2.COLOR_RGB2BGR)
        try:
            result_img = visualize_depth_map(depth_map, mode=mode, original_img=original_img_cv)
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
    else:
        result_img = visualize_depth_map(depth_map, mode=mode)

    # Converter o resultado para bytes (PNG)
    is_success, buffer = cv2.imencode(".png", result_img)
    if not is_success:
        raise HTTPException(status_code=500, detail="Falha ao gerar imagem.")
    io_buf = io.BytesIO(buffer)

    return StreamingResponse(io_buf, media_type="image/png")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api:app", host="0.0.0.0", port=8000, reload=True)