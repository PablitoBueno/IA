# -*- coding: utf-8 -*-
"""sentimentAnalysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17j1MIjMfZ2Dtevk4x9-BdHhnV17XJ3lT
"""

!pip install scikit-learn pandas transformers torch matplotlib joblib huggingface_hub

import json
import pandas as pd
import logging
from google.colab import files
from sklearn.feature_extraction.text import CountVectorizer
from transformers import pipeline
from huggingface_hub import login
import matplotlib.pyplot as plt
from joblib import Parallel, delayed

# Configuração do logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

# Login na Hugging Face
login(token="token")  # Substitua pelo seu token

# Upload do arquivo JSON
print("Por favor, faça o upload do arquivo JSON com os comentários.")
uploaded = files.upload()

# Exibir o nome do arquivo carregado
for file_name in uploaded.keys():
    logging.info(f"Arquivo carregado: {file_name}")

# Carregar os dados do arquivo JSON
with open(file_name, 'r', encoding='utf-8') as f:
    data = json.load(f)

# Função de pré-processamento
def limpar_texto(texto):
    """
    Limpa e pré-processa o texto:
    - Remove stopwords
    - Tokeniza e converte em uma string limpa
    """
    vectorizer = CountVectorizer(stop_words='english')  # Usa a stopword list embutida
    X = vectorizer.fit_transform([texto])  # Gera os tokens após remoção de stopwords
    tokens = vectorizer.get_feature_names_out()  # Extrai tokens limpos
    return " ".join(tokens)

# Carregar o pipeline para análise de sentimentos/emissões
sentiment_analysis = pipeline("text-classification", model="j-hartmann/emotion-english-distilroberta-base")

# Função para classificar sentimentos
def classificar_sentimento(texto):
    """
    Classifica o sentimento de um texto usando o modelo selecionado.
    """
    try:
        resultado = sentiment_analysis(texto)
        return resultado[0]['label'], resultado[0]['score']
    except Exception as e:
        logging.error(f"Erro ao classificar o texto: {texto} | Erro: {e}")
        return "Erro", 0.0

# Aplicar a limpeza e classificação de forma paralela para maior eficiência
data = Parallel(n_jobs=-1)(
    delayed(lambda x: {
        **x,
        'comentario_limpo': limpar_texto(x['comentario']),
        'sentimento': classificar_sentimento(limpar_texto(x['comentario']))[0],
        'score_sentimento': classificar_sentimento(limpar_texto(x['comentario']))[1]
    })(item) for item in data
)

# Converter os dados em um DataFrame para facilitar a visualização e análise
df = pd.DataFrame(data)

# Exibir os resultados no console
logging.info("Resultados da análise de sentimentos:")
print(df[['comentario', 'comentario_limpo', 'sentimento', 'score_sentimento']])

# Visualização da distribuição de sentimentos
sentimento_counts = df['sentimento'].value_counts()
sentimento_counts.plot(kind='bar', color='skyblue', title='Distribuição de Sentimentos/Emoções')
plt.xlabel('Sentimentos')
plt.ylabel('Frequência')
plt.show()