# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WVPNWIGgxYocV2jm_MDI8rI7e2hn5x-n
"""

# Instalando as bibliotecas necessárias (caso não estejam instaladas)
!pip install scikit-learn pandas transformers torch huggingface_hub

# Importação das bibliotecas
import json
import pandas as pd
from google.colab import files
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, CountVectorizer
from transformers import pipeline
from huggingface_hub import login

# Código para upload do arquivo sentimentos.json
uploaded = files.upload()

# Exibir o nome do arquivo carregado
for file_name in uploaded.keys():
    print(f'Arquivo carregado: {file_name}')

# Carregar os dados do arquivo JSON
with open(file_name, 'r', encoding='utf-8') as f:
    data = json.load(f)

# Função de pré-processamento utilizando scikit-learn
def limpar_texto(texto):
    """
    Função para limpar e pré-processar o texto usando o scikit-learn:
    - Converte para minúsculas
    - Remove caracteres especiais
    - Remove stopwords
    """
    # Converter para minúsculas
    texto_original = texto
    texto = texto.lower()

    # Remover caracteres não alfanuméricos
    texto = ''.join([char for char in texto if char.isalnum() or char.isspace()])

    # Tokenização e remoção de stopwords usando scikit-learn
    # Cria o CountVectorizer com stopwords em inglês, convertendo para uma lista
    vectorizer = CountVectorizer(stop_words=list(ENGLISH_STOP_WORDS)) # Convert ENGLISH_STOP_WORDS to a list
    X = vectorizer.fit_transform([texto])

    # Extrai as palavras (tokens) após a remoção de stopwords
    tokens = vectorizer.get_feature_names_out()

    # Junta os tokens limpos
    texto_limpo = " ".join(tokens)

    # Exibe o comentário original e o limpo
    print(f"Comentário Original: {texto_original}")
    print(f"Comentário Limpo: {texto_limpo}")
    print('-' * 80)

    return texto_limpo

# Aplicar a função de limpeza ao conteúdo e mostrar os resultados
for item in data:
    item['comentario_limpo'] = limpar_texto(item['comentario'])

# Carregar o pipeline para classificação de sentimentos com o modelo desejado
# Replace "MODEL_NAME" with the desired gated model from Hugging Face
# Login to Hugging Face (replace "YOUR_TOKEN" with your actual token)
login(token="code")
sentiment_analysis = pipeline("text-classification", model="bhadresh-savani/distilbert-base-uncased-emotion")

# Função para classificar os sentimentos com o modelo Transformers
def classificar_sentimento(texto):
    """
    Classifica o sentimento de um texto usando o modelo selecionado.
    """
    resultado = sentiment_analysis(texto)
    # Retorna o sentimento e a confiança do modelo
    return resultado[0]['label'], resultado[0]['score']

# Aplicar a classificação de sentimento a cada comentário
for item in data:
    sentimento, score = classificar_sentimento(item['comentario_limpo'])
    item['sentimento'] = sentimento
    item['score_sentimento'] = score

# Exibir os resultados
for item in data:
    print(f"Comentário: {item['comentario_limpo']}")
    print(f"Sentimento: {item['sentimento']} | Score: {item['score_sentimento']}")
    print('-' * 80)